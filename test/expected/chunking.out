-- Chunking test
-- This test verifies text chunking functionality
-- Test with short text (should return 1 chunk)
SELECT array_length(
    pgedge_vectorizer.chunk_text(
        'This is a short test.',
        'token_based',
        100,
        10
    ),
    1
) AS num_chunks;
 num_chunks 
------------
          1
(1 row)

-- Test with longer text (should return multiple chunks)
SELECT array_length(
    pgedge_vectorizer.chunk_text(
        repeat('This is a test sentence that will be repeated many times to create a long text. ', 50),
        'token_based',
        100,
        20
    ),
    1
) >= 2 AS has_multiple_chunks;
 has_multiple_chunks 
---------------------
 t
(1 row)

-- Test that chunks are returned
SELECT
    length(chunk) > 0 AS chunk_not_empty
FROM unnest(
    pgedge_vectorizer.chunk_text(
        'Test content for chunking',
        'token_based',
        100,
        10
    )
) AS chunk
LIMIT 1;
 chunk_not_empty 
-----------------
 t
(1 row)

-- Test default parameters
SELECT array_length(
    pgedge_vectorizer.chunk_text(
        'Test with default parameters'
    ),
    1
) AS chunks_with_defaults;
 chunks_with_defaults 
----------------------
                     
(1 row)

-- Test overlap chunking - verify chunks don't start mid-word
-- This tests the bug fix for corrupted chunks when overlap > 0
SELECT
    chunk,
    -- Verify chunk starts with a letter or quote (not mid-word)
    substring(chunk, 1, 1) ~ '^[A-Za-z"'']' AS starts_properly
FROM unnest(
    pgedge_vectorizer.chunk_text(
        'This is the first sentence. This is the second sentence. This is the third sentence. This is the fourth sentence.',
        'token_based',
        10,
        2
    )
) AS chunk;
            chunk             | starts_properly 
------------------------------+-----------------
 This is the first sentence.  | t
 This is the second sentence. | t
 This is the third sentence.  | t
 This is the fourth sentence. | t
(4 rows)

-- Test zero overlap (should work correctly)
SELECT
    chunk,
    substring(chunk, 1, 1) ~ '^[A-Za-z"'']' AS starts_properly
FROM unnest(
    pgedge_vectorizer.chunk_text(
        'First sentence here. Second sentence here. Third sentence here.',
        'token_based',
        5,
        0
    )
) AS chunk;
         chunk         | starts_properly 
-----------------------+-----------------
 First sentence here.  | t
 Second sentence here. | t
 Third sentence here.  | t
(3 rows)

-- Test large overlap (50%)
SELECT
    array_length(
        pgedge_vectorizer.chunk_text(
            'The quick brown fox jumps over the lazy dog. The quick brown fox jumps again.',
            'token_based',
            8,
            4
        ),
        1
    ) >= 1 AS large_overlap_works;
 large_overlap_works 
---------------------
 t
(1 row)

