-- Primary key types test
-- This test verifies that vectorization works with various primary key types
-- ============================================================================
-- Test 1: UUID primary key
-- ============================================================================
CREATE TABLE test_uuid_pk (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    content TEXT
);
-- Enable vectorization
SELECT pgedge_vectorizer.enable_vectorization(
    'test_uuid_pk'::regclass,
    'content',
    'token_based',
    100,
    10,
    1536
);
NOTICE:  Using primary key column: id (uuid)
NOTICE:  Vectorization enabled: test_uuid_pk -> test_uuid_pk_content_chunks
NOTICE:  Strategy: token_based, chunk_size: 100, overlap: 10
NOTICE:  Processing existing rows...
NOTICE:  Processed 0 existing rows
 enable_vectorization 
----------------------
 
(1 row)

-- Verify source_id column type matches UUID
SELECT data_type
FROM information_schema.columns
WHERE table_name = 'test_uuid_pk_content_chunks'
AND column_name = 'source_id';
 data_type 
-----------
 uuid
(1 row)

-- Insert a test document
INSERT INTO test_uuid_pk (content)
VALUES ('This document has a UUID primary key.');
-- Verify chunks were created
SELECT COUNT(*) > 0 AS chunks_created FROM test_uuid_pk_content_chunks;
 chunks_created 
----------------
 t
(1 row)

-- Test UPDATE
UPDATE test_uuid_pk SET content = 'Updated UUID document content.';
-- Verify chunks still exist after update
SELECT COUNT(*) > 0 AS chunks_after_update FROM test_uuid_pk_content_chunks;
 chunks_after_update 
---------------------
 t
(1 row)

-- Clean up
DELETE FROM pgedge_vectorizer.queue WHERE chunk_table = 'test_uuid_pk_content_chunks';
SELECT pgedge_vectorizer.disable_vectorization('test_uuid_pk'::regclass, 'content', true);
NOTICE:  Vectorization disabled and chunk table dropped: test_uuid_pk_content_chunks
 disable_vectorization 
-----------------------
 
(1 row)

DROP TABLE test_uuid_pk;
-- ============================================================================
-- Test 2: INTEGER (SERIAL) primary key
-- ============================================================================
CREATE TABLE test_serial_pk (
    id SERIAL PRIMARY KEY,
    content TEXT
);
-- Enable vectorization
SELECT pgedge_vectorizer.enable_vectorization(
    'test_serial_pk'::regclass,
    'content',
    'token_based',
    100,
    10,
    1536
);
NOTICE:  Using primary key column: id (integer)
NOTICE:  Vectorization enabled: test_serial_pk -> test_serial_pk_content_chunks
NOTICE:  Strategy: token_based, chunk_size: 100, overlap: 10
NOTICE:  Processing existing rows...
NOTICE:  Processed 0 existing rows
 enable_vectorization 
----------------------
 
(1 row)

-- Verify source_id column type matches integer
SELECT data_type
FROM information_schema.columns
WHERE table_name = 'test_serial_pk_content_chunks'
AND column_name = 'source_id';
 data_type 
-----------
 integer
(1 row)

-- Insert a test document
INSERT INTO test_serial_pk (content)
VALUES ('This document has an integer primary key.');
-- Verify chunks were created
SELECT COUNT(*) > 0 AS chunks_created FROM test_serial_pk_content_chunks;
 chunks_created 
----------------
 t
(1 row)

-- Clean up
DELETE FROM pgedge_vectorizer.queue WHERE chunk_table = 'test_serial_pk_content_chunks';
SELECT pgedge_vectorizer.disable_vectorization('test_serial_pk'::regclass, 'content', true);
NOTICE:  Vectorization disabled and chunk table dropped: test_serial_pk_content_chunks
 disable_vectorization 
-----------------------
 
(1 row)

DROP TABLE test_serial_pk;
-- ============================================================================
-- Test 3: BIGINT primary key (regression test)
-- ============================================================================
CREATE TABLE test_bigint_pk (
    id BIGSERIAL PRIMARY KEY,
    content TEXT
);
-- Enable vectorization
SELECT pgedge_vectorizer.enable_vectorization(
    'test_bigint_pk'::regclass,
    'content',
    'token_based',
    100,
    10,
    1536
);
NOTICE:  Using primary key column: id (bigint)
NOTICE:  Vectorization enabled: test_bigint_pk -> test_bigint_pk_content_chunks
NOTICE:  Strategy: token_based, chunk_size: 100, overlap: 10
NOTICE:  Processing existing rows...
NOTICE:  Processed 0 existing rows
 enable_vectorization 
----------------------
 
(1 row)

-- Verify source_id column type matches bigint
SELECT data_type
FROM information_schema.columns
WHERE table_name = 'test_bigint_pk_content_chunks'
AND column_name = 'source_id';
 data_type 
-----------
 bigint
(1 row)

-- Insert a test document
INSERT INTO test_bigint_pk (content)
VALUES ('This document has a bigint primary key.');
-- Verify chunks were created
SELECT COUNT(*) > 0 AS chunks_created FROM test_bigint_pk_content_chunks;
 chunks_created 
----------------
 t
(1 row)

-- Clean up
DELETE FROM pgedge_vectorizer.queue WHERE chunk_table = 'test_bigint_pk_content_chunks';
SELECT pgedge_vectorizer.disable_vectorization('test_bigint_pk'::regclass, 'content', true);
NOTICE:  Vectorization disabled and chunk table dropped: test_bigint_pk_content_chunks
 disable_vectorization 
-----------------------
 
(1 row)

DROP TABLE test_bigint_pk;
-- ============================================================================
-- Test 4: TEXT primary key (slug-style)
-- ============================================================================
CREATE TABLE test_text_pk (
    slug TEXT PRIMARY KEY,
    content TEXT
);
-- Enable vectorization
SELECT pgedge_vectorizer.enable_vectorization(
    'test_text_pk'::regclass,
    'content',
    'token_based',
    100,
    10,
    1536
);
NOTICE:  Using primary key column: slug (text)
NOTICE:  Vectorization enabled: test_text_pk -> test_text_pk_content_chunks
NOTICE:  Strategy: token_based, chunk_size: 100, overlap: 10
NOTICE:  Processing existing rows...
NOTICE:  Processed 0 existing rows
 enable_vectorization 
----------------------
 
(1 row)

-- Verify source_id column type matches text
SELECT data_type
FROM information_schema.columns
WHERE table_name = 'test_text_pk_content_chunks'
AND column_name = 'source_id';
 data_type 
-----------
 text
(1 row)

-- Insert a test document with a slug value
INSERT INTO test_text_pk (slug, content)
VALUES ('my-great-article', 'This document uses a text slug as primary key.');
-- Verify chunks were created
SELECT COUNT(*) > 0 AS chunks_created FROM test_text_pk_content_chunks;
 chunks_created 
----------------
 t
(1 row)

-- Verify the actual source_id value stored
SELECT source_id FROM test_text_pk_content_chunks LIMIT 1;
    source_id     
------------------
 my-great-article
(1 row)

-- Clean up
DELETE FROM pgedge_vectorizer.queue WHERE chunk_table = 'test_text_pk_content_chunks';
SELECT pgedge_vectorizer.disable_vectorization('test_text_pk'::regclass, 'content', true);
NOTICE:  Vectorization disabled and chunk table dropped: test_text_pk_content_chunks
 disable_vectorization 
-----------------------
 
(1 row)

DROP TABLE test_text_pk;
-- ============================================================================
-- Test 5: VARCHAR(26) primary key (ULID-style)
-- ============================================================================
CREATE TABLE test_varchar_pk (
    id VARCHAR(26) PRIMARY KEY,
    content TEXT
);
-- Enable vectorization
SELECT pgedge_vectorizer.enable_vectorization(
    'test_varchar_pk'::regclass,
    'content',
    'token_based',
    100,
    10,
    1536
);
NOTICE:  Using primary key column: id (character varying(26))
NOTICE:  Vectorization enabled: test_varchar_pk -> test_varchar_pk_content_chunks
NOTICE:  Strategy: token_based, chunk_size: 100, overlap: 10
NOTICE:  Processing existing rows...
NOTICE:  Processed 0 existing rows
 enable_vectorization 
----------------------
 
(1 row)

-- Verify source_id column type matches character varying
SELECT data_type
FROM information_schema.columns
WHERE table_name = 'test_varchar_pk_content_chunks'
AND column_name = 'source_id';
     data_type     
-------------------
 character varying
(1 row)

-- Insert a test document with a ULID-style value
INSERT INTO test_varchar_pk (id, content)
VALUES ('01HZXK5V3RQJF8N2GYTP4M', 'This document uses a VARCHAR ULID-style primary key.');
-- Verify chunks were created
SELECT COUNT(*) > 0 AS chunks_created FROM test_varchar_pk_content_chunks;
 chunks_created 
----------------
 t
(1 row)

-- Clean up
DELETE FROM pgedge_vectorizer.queue WHERE chunk_table = 'test_varchar_pk_content_chunks';
SELECT pgedge_vectorizer.disable_vectorization('test_varchar_pk'::regclass, 'content', true);
NOTICE:  Vectorization disabled and chunk table dropped: test_varchar_pk_content_chunks
 disable_vectorization 
-----------------------
 
(1 row)

DROP TABLE test_varchar_pk;
-- ============================================================================
-- Test 6: BIGINT primary key named record_num (auto-detection)
-- ============================================================================
CREATE TABLE test_autodetect_pk (
    record_num BIGSERIAL PRIMARY KEY,
    content TEXT
);
-- Enable vectorization WITHOUT passing source_pk
-- Auto-detection should find 'record_num' from pg_index
SELECT pgedge_vectorizer.enable_vectorization(
    'test_autodetect_pk'::regclass,
    'content',
    'token_based',
    100,
    10,
    1536
);
NOTICE:  Using primary key column: record_num (bigint)
NOTICE:  Vectorization enabled: test_autodetect_pk -> test_autodetect_pk_content_chunks
NOTICE:  Strategy: token_based, chunk_size: 100, overlap: 10
NOTICE:  Processing existing rows...
NOTICE:  Processed 0 existing rows
 enable_vectorization 
----------------------
 
(1 row)

-- Verify source_id column type matches bigint
SELECT data_type
FROM information_schema.columns
WHERE table_name = 'test_autodetect_pk_content_chunks'
AND column_name = 'source_id';
 data_type 
-----------
 bigint
(1 row)

-- Insert a test document
INSERT INTO test_autodetect_pk (content)
VALUES ('This document uses an auto-detected primary key.');
-- Verify chunks were created
SELECT COUNT(*) > 0 AS chunks_created FROM test_autodetect_pk_content_chunks;
 chunks_created 
----------------
 t
(1 row)

-- Clean up
DELETE FROM pgedge_vectorizer.queue WHERE chunk_table = 'test_autodetect_pk_content_chunks';
SELECT pgedge_vectorizer.disable_vectorization('test_autodetect_pk'::regclass, 'content', true);
NOTICE:  Vectorization disabled and chunk table dropped: test_autodetect_pk_content_chunks
 disable_vectorization 
-----------------------
 
(1 row)

DROP TABLE test_autodetect_pk;
-- ============================================================================
-- Test 7: Composite primary key (error case)
-- ============================================================================
CREATE TABLE test_composite_pk (
    tenant_id INT NOT NULL,
    item_id INT NOT NULL,
    content TEXT,
    PRIMARY KEY (tenant_id, item_id)
);
-- This should raise an error because composite PKs are not supported
SELECT pgedge_vectorizer.enable_vectorization(
    'test_composite_pk'::regclass,
    'content',
    'token_based',
    100,
    10,
    1536
);
ERROR:  Table test_composite_pk has a composite primary key (2 columns), which is not supported by auto-detection. Use the source_pk parameter to specify a single column.
CONTEXT:  PL/pgSQL function pgedge_vectorizer.enable_vectorization(regclass,name,text,integer,integer,integer,text,name) line 40 at RAISE
-- Clean up (no vectorization to disable, just drop the table)
DROP TABLE test_composite_pk;
-- ============================================================================
-- Test 7a: Composite primary key with explicit source_pk (should succeed)
-- ============================================================================
CREATE TABLE test_composite_override (
    tenant_id INT NOT NULL,
    item_id INT NOT NULL,
    content TEXT,
    PRIMARY KEY (tenant_id, item_id)
);
-- This should succeed because we specify which column to use
-- Note: source_pk must be globally unique to avoid UNIQUE(source_id, chunk_index) conflicts
SELECT pgedge_vectorizer.enable_vectorization(
    'test_composite_override'::regclass, 'content', 'token_based', 100, 10, 1536, NULL, 'item_id'
);
NOTICE:  Using primary key column: item_id (integer)
NOTICE:  Vectorization enabled: test_composite_override -> test_composite_override_content_chunks
NOTICE:  Strategy: token_based, chunk_size: 100, overlap: 10
NOTICE:  Processing existing rows...
NOTICE:  Processed 0 existing rows
 enable_vectorization 
----------------------
 
(1 row)

-- Verify source_id column type matches integer
SELECT data_type
FROM information_schema.columns
WHERE table_name = 'test_composite_override_content_chunks'
AND column_name = 'source_id';
 data_type 
-----------
 integer
(1 row)

-- Insert a test document with unique item_id
INSERT INTO test_composite_override (tenant_id, item_id, content)
VALUES (1, 42, 'Document in a composite PK table with explicit source_pk.');
-- Verify chunks were created
SELECT COUNT(*) > 0 AS chunks_created FROM test_composite_override_content_chunks;
 chunks_created 
----------------
 t
(1 row)

-- Insert a second row with the SAME item_id but different tenant_id.
-- This demonstrates the uniqueness conflict: source_pk must be globally
-- unique, not just unique within the composite key.
INSERT INTO test_composite_override (tenant_id, item_id, content)
VALUES (2, 42, 'Different tenant, same item_id â€” will conflict on chunk table.');
-- Verify the conflict: the second insert's trigger overwrites the first
-- row's chunks because they share the same source_id (42)
SELECT COUNT(*) AS chunk_count FROM test_composite_override_content_chunks WHERE source_id = 42;
 chunk_count 
-------------
           1
(1 row)

-- Clean up
DELETE FROM pgedge_vectorizer.queue WHERE chunk_table = 'test_composite_override_content_chunks';
SELECT pgedge_vectorizer.disable_vectorization('test_composite_override'::regclass, 'content', true);
NOTICE:  Vectorization disabled and chunk table dropped: test_composite_override_content_chunks
 disable_vectorization 
-----------------------
 
(1 row)

DROP TABLE test_composite_override;
-- ============================================================================
-- Test 7b: No primary key (error case)
-- ============================================================================
CREATE TABLE test_no_pk (
    item_id INT NOT NULL,
    content TEXT
);
-- This should raise an error because the table has no primary key
SELECT pgedge_vectorizer.enable_vectorization(
    'test_no_pk'::regclass,
    'content',
    'token_based',
    100,
    10,
    1536
);
ERROR:  Table test_no_pk has no primary key. Use the source_pk parameter to specify the column to use as document identifier.
CONTEXT:  PL/pgSQL function pgedge_vectorizer.enable_vectorization(regclass,name,text,integer,integer,integer,text,name) line 35 at RAISE
-- Clean up
DROP TABLE test_no_pk;
-- ============================================================================
-- Test 8: Explicit source_pk override
-- ============================================================================
CREATE TABLE test_override_pk (
    id BIGSERIAL PRIMARY KEY,
    external_id UUID NOT NULL DEFAULT gen_random_uuid(),
    content TEXT
);
-- Enable vectorization with explicit source_pk override using positional args
-- Pass NULL for chunk_table_name, 'external_id' for source_pk
SELECT pgedge_vectorizer.enable_vectorization(
    'test_override_pk'::regclass, 'content', 'token_based', 100, 10, 1536, NULL, 'external_id'
);
NOTICE:  Using primary key column: external_id (uuid)
NOTICE:  Vectorization enabled: test_override_pk -> test_override_pk_content_chunks
NOTICE:  Strategy: token_based, chunk_size: 100, overlap: 10
NOTICE:  Processing existing rows...
NOTICE:  Processed 0 existing rows
 enable_vectorization 
----------------------
 
(1 row)

-- Verify source_id column type matches uuid (from external_id, not bigint from id)
SELECT data_type
FROM information_schema.columns
WHERE table_name = 'test_override_pk_content_chunks'
AND column_name = 'source_id';
 data_type 
-----------
 uuid
(1 row)

-- Insert a test document
INSERT INTO test_override_pk (content)
VALUES ('This document uses an overridden primary key column.');
-- Verify chunks were created
SELECT COUNT(*) > 0 AS chunks_created FROM test_override_pk_content_chunks;
 chunks_created 
----------------
 t
(1 row)

-- Clean up
DELETE FROM pgedge_vectorizer.queue WHERE chunk_table = 'test_override_pk_content_chunks';
SELECT pgedge_vectorizer.disable_vectorization('test_override_pk'::regclass, 'content', true);
NOTICE:  Vectorization disabled and chunk table dropped: test_override_pk_content_chunks
 disable_vectorization 
-----------------------
 
(1 row)

DROP TABLE test_override_pk;
